---
title: "Introduction to Bayesian computation using the rstanarm R package (goodrich)"
format: 
   html:
     df-print: paged
---

<https://www.youtube.com/watch?v=z7zOzL9Rrzs>

formula syntax: <https://www.jstatsoft.org/article/view/v067i01>

## What is Stan?

A probabilistic programming language.

## What is the rstanarm R package?

-   An R interface to a handful of pre-written, pre-compiled Stan programs

-   rstanarm syntax mirrors that of popular model-fitting functions in R, including:

    -   `lm` and `aov`

    -   `glm` and `MASS::glm.nb`

    -   `MASS::polr`

    -   `lme4::lmer` and `lme4::glmer`

    -   `gamm4::gamm4`

-   Use Stan without knowing the Stan language

-   Minimal installation requirements, i.e., no C++ compiler is required

## Source of uncertainty in statistical inference

Taking expectations averages over uncertainty in the unknowns. What are the sources of this uncertainty?

1.  Model uncertainty: Which model(s) should be used?

2.  Parameter uncertainty: What are the parameter values in the model(s)?

3.  Systematic uncertainty: What system of reasoning should be used to evaluate the implications of the model(s)?

4.  Software uncertainty: Does the software successfully estimate the parameter values?

Bayesian approach accounts for (1), (2) and (3). Probability is the system of reasoning, so both model and parameter uncertainty are expressed in terms of probability. Stan substantially mitigates (4).

Supervised learning approaches leave (3) open, typically ignore (2), and focus on the choice of the best model but do not quantify model uncertainty (1).

Frequentist approach also uses probability for (3) but interprets it as uncertainty over repeated applications of the estimator to independent samples from the same population. So, it does not really quantify model (1) or parameter (2) uncertainty.

## Bayesian inference

To update your beliefs using Bayes' rule you need four things:

1.  A probability distribution for the data-generating process that typically depends on parameters

2.  A description of your current beliefs about those parameters using probability distributions

3.  Data, although it need NOT be a random sample from a well-defined population.

4.  An algorithm to draw from the implied posterior distribution

Stan does (4) very well for many posterior distributions but you are on your own for (1), (2) and (3).

The rstanarm R package provides a menu of choices for (1) and (2).

\(1\) + (2) = generative model

## Lending Club data

<https://www.openintro.org/data/index.php?data=loans_full_schema>

```{r}
#| output: false
library(tidyverse)
library(magrittr)
library(rstanarm)
options(mc.cores = parallel::detectCores())
set.seed(20230119)

if (!file.exists("data/lendingclub.tsv")) download.file("https://www.openintro.org/data/tab-delimited/loans_full_schema.txt", "data/lendingclub.tsv")
```

```{r}
df = read_tsv("data/lendingclub.tsv", show_col_types = FALSE)

df %>% count(grade)

df %<>%
  select(grade,
         loan_amount,
         term,
         homeownership,
         annual_income,
         emp_length) %>%
  filter(complete.cases(.)) %>%
  mutate(lowgrade = ifelse(grade %in% c("D", "E", "F", "G"), 1, 0))

df
```

## Fitting to simulated data

```{r}
lowgrade_sim = rbinom(n = nrow(df), size = 1, prob = ifelse(df$emp_length == 0, 0.5, 0.1))

table(lowgrade_sim)
```

```{r}
#| output: false
post_sim = stan_glm(lowgrade_sim ~ I(emp_length != 0),
                    family = binomial(link = "logit"),
                    prior = normal(),
                    prior_intercept = normal(),
                    data = df)
```

```{r}
plot(post_sim)
```

```{r}
#| output: false
post = stan_glm(lowgrade ~ I(emp_length != 0) + log(loan_amount) + log(annual_income + 1) + homeownership + term,
                family = binomial(link = "logit"),
                prior = normal(),
                prior_intercept = normal(),
                QR = TRUE,
                data = df)
```

```{r}
plot(post)
```

## Session info

```{r}
sessioninfo::session_info()
```
