---
title: "Introduction to probability theory"
format: html
---

## LECTURE 1: XXX

## LECTURE 2: XXX

## LECTURE 3: XXX

## LECTURE 4: XXX

## LECTURE 5: Discrete random variables

### Functions

A function is a procedure that assigns an element of set $Y$ to each element of set $X$ (often also referred to as a mapping).

$$
f : X \rightarrow Y
$$

More precisely, a function is a set of pairs $(x, y)$ such that $x \in X$, $y \in Y$ and each $x$ appears in exactly one pair.

For example, for the "square" function $f(x) = x^2$:

$X = \{ -1, 0, 1, 2 \}$

$Y = \mathbb{R}$

$f = \{ (-1, 1), (0,0), (1,1), (2, 4) \}$

A function can also be described by a table:

| $x$ | $y = x^2$ |
|-----|-----------|
| -1  | 1         |
| 0   | 0         |
| 1   | 1         |
| 2   | 4         |

A function can also be described by a set of points in a plot.

For example, the "square" function $f : \mathbb{R} \rightarrow \mathbb{R}$ $f(x) = x^2$ can also be described by a parabula in a plot, where each pair $(x, y = x^2)$ is a point on the parabula.

![<https://en.wikipedia.org/wiki/Function_(mathematics)>](function.png){width="50%"}

For example, probability $P$ is a function ("probability law") that assigns a real number $\mathbb{R}$ to each element $E$ of the event space $\Sigma$ (i.e., the set containing each subset of the sample space $\Omega$, i.e., the "power set" $2^{\Omega}$ or, more precisely, the $\sigma$-algebra $A$):

$P : \Sigma \rightarrow \mathbb{R}$

such that:

-   $P(E) \ge 0$
-   $P(\Omega) = 1$
-   $P(\cup^{\infty}_{i=1}E_i) = \sum^{\infty}_{i=1}P(E_i) : \forall$ mutually exclusive events $E_1, E_2, \ldots \in \Sigma$

Probability (i.e., the probability function $P$) is a measure of how likely an event is to occur or a statement is to be true. A **measure** $\mu$ is a function from a $\sigma$-algebra $\Sigma$ over set $\Omega$ to the real numbers $\mathbb{R}$

$$
\mu : \Sigma \rightarrow \mathbb{R}
$$

such that:

-   **Non-negativity**: $\mu(E) \ge 0 : \forall E \in \Sigma$
-   $\mu(\emptyset) = 0$
-   **Countable additivity**: $\forall$ countable collections $\{ E_i\}_{i =1}^{\infty}$ of pairwise disjoint sets $E_1, E_2, \ldots \in \Sigma$

$$
\mu(\cup^{\infty}_{i=1}E_i) = \sum^{\infty}_{i=1}\mu(E_i)
$$

The pair $(\Omega, \Sigma)$ is called a **measurable space**, and the members of $\Sigma$ are called **measurable sets**.

The triple $(\Omega, \Sigma, \mu)$ is called a **measure space**.

A probability measure is a measure with total measure one -- that is, $\mu(\Omega) = 1$. A probability space is a measure space with a probability measure.

### Random variables

-   A random variable is a numerical quantity whose value is determined by the outcome of a random experiment.
-   A random variable ($X$) is a function that assigns a real number $x \in \mathbb{R}$ to every possible outcome $\omega \in \Omega = \{ \omega_1, \omega_2, \ldots, \omega_n \}$ of a random experiment.
-   A random variable is a function from the sample space to the real numbers.
-   A random variable is a function that takes the outcome of a random experiment as input and returns a real number as output, for example:

$$
X(\omega_1) = 5
$$

-   A random variable often describes a measurable quantity associated with the outcome of random experiment or it indicates whether an event ($A$) has occurred (e.g., $x = 1$ if $\omega_1 \in A$ or $x = 0$ if $\omega_1 \notin A$).
-   One or more random variables can be defined on the same sample space.
-   A function of one or more random variables is also a random variable.

### Probability mass function (PMF) of a discrete r.v.

-   The PMF is the "probability law" or "probability distribution" of $X$.
-   $X = x$ is an event, i.e., a subset of the sample space $\Omega = \{ \omega_1, \omega_2, \ldots, \omega_n \}$:

$$
\{\omega \in \Omega: X(\omega) = x \}
$$

-   $P(X = x) = p_X(x) = P(\{ \omega \in \Omega : X(\omega) = x \})$
-   $P(X = x) \ge 0$
-   $\sum_x P(X = x) =1$

### Expected value: a measure of the center of a PMF

$$
E[X] = \sum_x x P(X = x)
$$

### Expected value rule

$E[g(X)]$

$Y = g(X)$

$E[Y] = \sum_y y P(Y = y)$

$E[Y] = E[g(X)] = \sum_x g(x) P(X = x)$

For example:

$E[X^{2}] = \sum_x x^2 P(X = x)$

In general:

$E[g(X)] \ne g(E[X])$

For example:

$E[X^2] \ne E[X]^2$

### Linearity of expectation

The exception to the general rule above is when $g(X)$ is a linear function:

$Y = g(X) = aX + b$

$E[Y] = E[g(X)] = E[aX + b] = aE[X] + b$

## LECTURE 6: Variance; Conditioning a r.v. on an event; Multiple random variables

### Variance: a measure of the spread of a PMF

-   Random variable $X$ with mean $\mu = E[X]$
-   Distance from the mean: $X - \mu$
-   Average distance from the mean: $E[X - \mu] = E[X] - \mu = \mu - \mu = 0$
-   Variance = average of the squared distance from the mean:

$$
E[(X - \mu)^2] = \text{Var}(X) = \sigma_X^2  \ge 0
$$

-   Using the expected value rule:

$$
\sigma^2 = \text{Var}(X) = E[(X - \mu)^2] = \sum_x(x - \mu)^2 P(X = x)
$$

-   Standard deviation = square root of the variance (has the same unit of measurement as the r.v.):

$$
\sigma_X = \sqrt{\sigma_X^2} = \sqrt{\text{Var}(X)}
$$

#### Properties of the variance

-   Let $Y = aX + b$: $\text{Var}(Y) = \text{Var}(aX + b) = a^2\text{Var}(X)$
-   A useful formula: $\text{Var}(X) = E[X^2] - (E[X])^2$

#### Variance of Bernoulli and uniform r.v.

Bernoulli: $\text{Var(X)} = p (1 - p)$

Uniform: $n = (b - a)$ $\text{Var(X)} = \frac{1}{12}n(n+2)$

### Conditional PMF, expectation and variance

-   $p_{X \mid A}(x) = P(X = x \mid A)$
-   $\sum_x p_{X \mid A}(x) = 1$
-   $E[X \mid A] = \sum_x x p_{X \mid A}(x)$
-   $E[g(X) \mid A] = \sum_x g(x) p_{X \mid A}(x)$

Conditional PMFs, expectations and variances are the same as the unconditional ones except that we use conditional probabilities rather than unconditional probabilities.

#### Total expectation theorem

XXX
