<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Edoardo “Dado” Marcora">
<meta name="dcterms.date" content="2023-04-07">

<title>Statistical inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="king2_files/libs/clipboard/clipboard.min.js"></script>
<script src="king2_files/libs/quarto-html/quarto.js"></script>
<script src="king2_files/libs/quarto-html/popper.min.js"></script>
<script src="king2_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="king2_files/libs/quarto-html/anchor.min.js"></script>
<link href="king2_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="king2_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="king2_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="king2_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="king2_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#reasoning-under-uncertainty" id="toc-reasoning-under-uncertainty" class="nav-link active" data-scroll-target="#reasoning-under-uncertainty">Reasoning under uncertainty</a>
  <ul class="collapse">
  <li><a href="#axioms-of-probability-theory" id="toc-axioms-of-probability-theory" class="nav-link" data-scroll-target="#axioms-of-probability-theory">Axioms of probability theory</a></li>
  <li><a href="#theorems-a.k.a.-rules-of-probability-theory" id="toc-theorems-a.k.a.-rules-of-probability-theory" class="nav-link" data-scroll-target="#theorems-a.k.a.-rules-of-probability-theory">Theorems (a.k.a. rules) of probability theory</a></li>
  <li><a href="#definitions-of-probability-theory" id="toc-definitions-of-probability-theory" class="nav-link" data-scroll-target="#definitions-of-probability-theory">Definitions of probability theory</a></li>
  <li><a href="#bayes-theoremrule" id="toc-bayes-theoremrule" class="nav-link" data-scroll-target="#bayes-theoremrule">Bayes’ theorem/rule</a></li>
  <li><a href="#frequentist-vs-bayesian-uncertainty" id="toc-frequentist-vs-bayesian-uncertainty" class="nav-link" data-scroll-target="#frequentist-vs-bayesian-uncertainty">Frequentist vs Bayesian uncertainty</a></li>
  <li><a href="#frequentist-vs-bayesian-inference" id="toc-frequentist-vs-bayesian-inference" class="nav-link" data-scroll-target="#frequentist-vs-bayesian-inference">Frequentist vs Bayesian inference</a></li>
  </ul></li>
  <li><a href="#probability-vs-likelihood" id="toc-probability-vs-likelihood" class="nav-link" data-scroll-target="#probability-vs-likelihood">Probability vs likelihood</a></li>
  <li><a href="#statistical-thinking" id="toc-statistical-thinking" class="nav-link" data-scroll-target="#statistical-thinking">Statistical thinking</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="king2.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Statistical inference</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Edoardo “Dado” Marcora </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 7, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="reasoning-under-uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="reasoning-under-uncertainty">Reasoning under uncertainty</h2>
<p><a href="https://pages.cs.wisc.edu/~dyer/cs540/notes/uncertainty.html" class="uri">https://pages.cs.wisc.edu/~dyer/cs540/notes/uncertainty.html</a></p>
<p>Reasoning = the process of thinking about something in a logical way in order to form a conclusion or judgment | the drawing of inferences or conclusions through the use of reason</p>
<ul>
<li><p>Agents (and people) want to make rational decisions even when they are not certain about the truth or falsity of a proposition.</p></li>
<li><p>Rather than reasoning about the truth or falsity of a proposition, reason about the belief that a proposition (or an event) is true (or is going to happen).</p></li>
<li><p>For each primitive proposition (or event), attach a <strong>degree of belief</strong> to the sentence.</p></li>
<li><p>Use <strong>probability theory</strong> as a formal method of manipulating degrees of belief.</p></li>
<li><p>Given a proposition, A, assign a probability, P(A), such that 0 &lt;= P(A) &lt;= 1, where if A is true, P(A)=1, and if A is false, P(A)=0. Proposition A must be either true or false, but P(A) summarizes our degree of belief in A being true.</p></li>
<li><p>Obtaining and Interpreting Probabilities<br>
There are several senses in which probabilities can be obtained and interpreted, among them the following:</p>
<ul>
<li><p><strong>Frequentist Interpretation</strong><br>
The probability is a property of a population of similar events. E.g., if set S = P union N, and P intersection N is the empty set, then the probability of an object being in set P is |P|/|S|. Hence, in this interpretation probabilities come from experiments and determining the population associated with a given proposition.</p></li>
<li><p><strong>Subjectivist Interpretation</strong><br>
A subjective degree of belief in a proposition or the occurrence of an event. E.g., the probability that you’ll pass the Final Exam based on your own subjective evaluation of the amount of studying you’ve done and your understanding of the material. Hence, in this interpretation probabilities characterize the agent’s beliefs.</p></li>
</ul></li>
</ul>
<section id="axioms-of-probability-theory" class="level3">
<h3 class="anchored" data-anchor-id="axioms-of-probability-theory">Axioms of probability theory</h3>
<p><a href="https://youtu.be/ID7J-LFSp3c" class="uri">https://youtu.be/ID7J-LFSp3c</a></p>
<ul>
<li><p><span class="math inline">\(\Omega\)</span>: a finite set (the <strong>sample space</strong>)</p></li>
<li><p><span class="math inline">\(A\)</span>: any subset of <span class="math inline">\(\Omega\)</span> (an <strong>event</strong>), <span class="math inline">\(A \subseteq \Omega\)</span></p></li>
<li><p><span class="math inline">\(P(A)\)</span>: the <strong>probability</strong> of <span class="math inline">\(A\)</span> is a function that, given an event, returns a real number and satisfies the following axioms:</p>
<ul>
<li><p><span class="math inline">\(P(A) \ge 0\)</span></p></li>
<li><p><span class="math inline">\(P(\Omega) = 1\)</span></p></li>
<li><p><span class="math inline">\(P(A \cup B) = P(A) + P(B)\)</span> if <span class="math inline">\(A \cap B = \varnothing\)</span></p>
<p>If <span class="math inline">\(\Omega\)</span> is an infinite set, the last axiom becomes: for an infinite sequence of disjoint subsets/events <span class="math inline">\(A_1, A_2, \ldots\)</span></p></li>
<li><p><span class="math inline">\(P(\cup_{i=1}^{\infty}{A_i}) = \sum_{i=1}^{\infty}{P(A_i)}\)</span></p></li>
</ul></li>
</ul>
</section>
<section id="theorems-a.k.a.-rules-of-probability-theory" class="level3">
<h3 class="anchored" data-anchor-id="theorems-a.k.a.-rules-of-probability-theory">Theorems (a.k.a. rules) of probability theory</h3>
<ul>
<li><p><span class="math inline">\(P(A) \le 1\)</span></p></li>
<li><p><span class="math inline">\(P(\varnothing) = 0\)</span></p></li>
<li><p><span class="math inline">\(P(A') = 1 - P(A)\)</span></p></li>
<li><p><span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span></p></li>
</ul>
</section>
<section id="definitions-of-probability-theory" class="level3">
<h3 class="anchored" data-anchor-id="definitions-of-probability-theory">Definitions of probability theory</h3>
<ul>
<li><p><span class="math inline">\(P(A \cap B)\)</span> is the <strong>joint probability</strong> of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span></p></li>
<li><p><span class="math inline">\(P(A \mid B) = \frac{P(A \cap B)}{P(B)}\)</span> is the <strong>conditional probability</strong> of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span></p></li>
<li><p><span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>independent</strong> iff <span class="math inline">\(P(A \cap B) = P(A)P(B)\)</span></p></li>
<li><p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent then <span class="math inline">\(P(A \mid B) = P(A)\)</span></p></li>
</ul>
</section>
<section id="bayes-theoremrule" class="level3">
<h3 class="anchored" data-anchor-id="bayes-theoremrule">Bayes’ theorem/rule</h3>
<p><span class="math display">\[
P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}
\]</span></p>
</section>
<section id="frequentist-vs-bayesian-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="frequentist-vs-bayesian-uncertainty">Frequentist vs Bayesian uncertainty</h3>
</section>
<section id="frequentist-vs-bayesian-inference" class="level3">
<h3 class="anchored" data-anchor-id="frequentist-vs-bayesian-inference">Frequentist vs Bayesian inference</h3>
<p><a href="https://www.health.ny.gov/diseases/chronic/discreen.htm" class="uri">https://www.health.ny.gov/diseases/chronic/discreen.htm</a></p>
<p>Sensitivity and specificity are measures of a test’s ability to correctly classify a person as having a disease or not having a disease. Sensitivity refers to a test’s ability to designate an individual with disease as positive. A highly sensitive test means that there are few false negative results, and thus fewer cases that have the disease are missed. The specificity of a test is its ability to designate an individual who does not have a disease as negative. A highly specific test means that there are few false positive results, and thus fewer cases that do not have the disease are misdiagnosed. It is desirable to have a test that is both highly sensitive and highly specific. This is frequently not possible. Typically there is a trade-off.</p>
<p>The probability of having the disease, given the results of a test, is called the predictive value of the test. Positive predictive value is the probability that a patient with a positive (abnormal) test result actually has the disease. Negative predictive value is the probability that a person with a negative (normal) test result is truly free of disease. Predictive value is an answer to the question: If my patient’s test result is positive, what are the chances that my patient does have the disease?</p>
<p>Predictive value is determined by the sensitivity and specificity of the test and the prevalence of disease in the population being tested. (Prevalence is defined as the proportion of persons in a defined population at a given point in time with the condition in question.) The more sensitive a test, the less likely an individual with a negative test will have the disease and thus the greater the negative predictive value. The more specific the test, the less likely an individual with a positive test will be free from disease and the greater the positive predictive value.</p>
<p>When the prevalence of preclinical disease is low, the positive predictive value will also be low, even using a test with high sensitivity and specificity. For such rare diseases, a large proportion of those with positive screening tests will inevitably be found not to have the disease upon further diagnostic testing. To increase the positive predictive value of a screening test, a program could target the screening test to those at high risk of developing the disease, based on considerations such as demographic factors, medical history or occupation. For example, mammograms are recommended for women over the age of forty, because that is a population with a higher prevalence of breast cancer.</p>
<p>PPV = (sensitivity x prevalence) / [ (sensitivity x prevalence) + ((1 – specificity) x (1 – prevalence)) ]</p>
<ul>
<li><p>Disease screening</p>
<ul>
<li><p><span class="math inline">\(P(T^- \mid D^-) = 0.95\)</span> (specificity)</p></li>
<li><p><span class="math inline">\(P(T^+ \mid D^-) = 1 - \text{specificity} = 0.05\)</span> (false positive a.k.a. type I error rate)</p></li>
<li><p><span class="math inline">\(P(T^+ \mid D^+) = 0.8\)</span> (sensitivity a.k.a. power)</p></li>
<li><p><span class="math inline">\(P(T^- \mid D^+) = 1 - \text{sensitivity} = 0.2\)</span> (false negative a.k.a. type II error rate)</p></li>
<li><p><span class="math inline">\(P(D^+) = 0.01\)</span> (prevalence)</p></li>
<li><p><span class="math inline">\(P(D^-) = 1 - \text{prevalence} = 0.99\)</span></p></li>
<li><p><span class="math inline">\(P(D^+ \mid T^+) = \frac{P(T^+ \mid D^+)P(D^+)}{P(T^+)} = \frac{P(T^+ \mid D^+)P(D^+)}{P(T^+ \mid D^+) P(D^+) + P(T^+ \mid D^-) P(D^-)}\)</span> (PPV)</p></li>
<li><p><span class="math inline">\(\text{PPV} = \frac{0.8 \times 0.01}{(0.8 \times 0.01) + (0.05 \times 0.99)} = 0.1391\)</span></p></li>
</ul></li>
<li><p>Null hypothesis significance testing (NHST)</p>
<ul>
<li><p><span class="math inline">\(P(S^- \mid H_0) = 0.95\)</span> (specificity)</p></li>
<li><p><span class="math inline">\(P(S^+ \mid H_0) = 0.05\)</span> (false positive a.k.a. type I error rate)</p></li>
<li><p><span class="math inline">\(P(S^+ \mid H_A) = 0.3\)</span> (sensitivity a.k.a. power)</p></li>
<li><p><span class="math inline">\(P(S^- \mid H_A) = 0.7\)</span> (false negative a.k.a. type II error rate)</p></li>
<li><p><span class="math inline">\(P(H_A) = 0.1\)</span> (prior)</p></li>
<li><p><span class="math inline">\(P(H_0) = 0.9\)</span></p></li>
<li><p><span class="math inline">\(P(H_A \mid S^+) = \frac{P(S^+ \mid H_A)P(H_A)}{P(S^+)} = \frac{P(S^+ \mid H_A)P(H_A)}{P(S^+ \mid H_A)P(H_A) + P(S^+ \mid H_0)P(H_0)}\)</span> (PPV)</p></li>
<li><p><span class="math inline">\(\text{PPV} = \frac{0.3 \times 0.1}{(0.3 \times 0.1) + (0.05 \times 0.9)} = 0.4615\)</span></p></li>
</ul></li>
</ul>
<p>Due to the low power of research studies and the publication bias for (statistically) significant and sensational findings, most published research findings are false!</p>
<p>Simply viewing an image of Rodin’s sculpture “The Thinker” promotes religious disbelief.</p>
<p><img src="the-thinker.webp" class="img-fluid" style="width:50.0%"></p>
<p><a href="https://www.science.org/doi/10.1126/science.1215647" class="uri">https://www.science.org/doi/10.1126/science.1215647</a></p>
<p><img src="science_the-thinker.png" class="img-fluid" style="width:50.0%"></p>
<p><img src="inference.png" class="img-fluid" style="width:60.0%"></p>
<p><img src="inference2.png" class="img-fluid" style="width:60.0%"></p>
</section>
</section>
<section id="probability-vs-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="probability-vs-likelihood">Probability vs likelihood</h2>
<p><a href="https://youtu.be/eDMGDhyDxuY" class="uri">https://youtu.be/eDMGDhyDxuY</a></p>
<p>Statisticians use <strong>probability</strong> to describe/quantify/measure <strong>uncertainty</strong></p>
<p>Probability is a well-defined mathematical concept, uncertainty is a ill-defined English word!</p>
<p>Frequentists and Bayesians disagree on what kind of uncertainty [aleatoric vs epistemic] can be described/measured using probability!</p>
<p>What is probability? What is uncertainty?</p>
<p>Probability is a measure [of the uncertainty] [of occurrence of an event]</p>
<p>Probability distributions allocate parcels of probability to each possible outcome [in the sample space, such that they sum to one]</p>
<p>Probability distributions are often described by mathematical equations that are defined by one or more parameters</p>
<p>Probability fixes parameters and varies data</p>
<p><span class="math inline">\(f(x) = p(x) = p(x \mid \Theta = \theta) = P(X = x \mid \Theta = \theta)\)</span> probability distribution (sums to 1)</p>
<p>Likelihood fixes data and varies parameters</p>
<p><span class="math inline">\(f(\theta) = l(\theta) = l(\theta \mid X = x) = P(X = x \mid \Theta = \theta)\)</span> not a probability distribution (does not sum to 1)</p>
<p>[what about a joint distribution of data and parameters? <a href="https://youtu.be/yakg94HyWdE" class="uri">https://youtu.be/yakg94HyWdE</a>]</p>
<p>Bayes’ theorem:</p>
<p><span class="math display">\[
P(\Theta = \theta \mid X = x) = \frac{P(\Theta = \theta)P(X = x \mid \Theta = \theta)}{P(X = x)}
\]</span></p>
<p><span class="math display">\[
p(\theta \mid X = x) \sim p(\theta) l(\theta \mid X = x)
\]</span></p>
<hr>
<p>Aleatoric and epistemic uncertainties are two types of uncertainties commonly encountered in probabilistic modeling and decision-making under uncertainty. They represent different sources and interpretations of uncertainty.</p>
<p><u>Aleatoric uncertainty</u>:</p>
<p>Aleatoric uncertainty, also known as statistical uncertainty or inherent uncertainty, arises from the inherent randomness or variability in the observed data. It is irreducible even with infinite amounts of data and reflects the inherent unpredictability of the system being modeled. Aleatoric uncertainty is often associated with noise or variability within the data itself. It can be thought of as the uncertainty that remains even when we have observed all there is to know about a particular phenomenon.</p>
<p><u>Epistemic uncertainty</u>:</p>
<p>Epistemic uncertainty, also known as model uncertainty or knowledge uncertainty, arises from the lack of knowledge or incomplete understanding about the underlying system being modeled. It is a result of limitations in the available data or the model’s inability to fully capture the true complexity of the system. Unlike aleatoric uncertainty, epistemic uncertainty can, in principle, be reduced with additional information or improved modeling techniques. It represents uncertainty that could be resolved with more data or a better model.</p>
<p>To summarize, aleatoric uncertainty represents the irreducible randomness or inherent variability in the data, while epistemic uncertainty arises from the lack of knowledge or incomplete understanding about the system being modeled. Aleatoric uncertainty cannot be reduced even with more data, while epistemic uncertainty can be reduced through further investigation, better data collection, or improved modeling techniques.</p>
</section>
<section id="statistical-thinking" class="level2">
<h2 class="anchored" data-anchor-id="statistical-thinking">Statistical thinking</h2>
<p><a href="https://youtu.be/be2wuOaglFY" class="uri">https://youtu.be/be2wuOaglFY</a></p>
<p>Statistics is mathematical modeling under uncertainty = statistical thinking!</p>
<p>Statistical thinking (the golden rules of statistics):</p>
<ol type="1">
<li><p>Know thy problem</p></li>
<li><p>Know thy tools (based on the problem)</p></li>
<li><p>Know thy data (based on the problem)</p></li>
</ol>
<p>opposite flow compared to STAT 101 (data myopia):</p>
<ol type="1">
<li><p>Look at the data</p></li>
<li><p>Pick a test (based on the data)</p></li>
<li><p>Calculate p-value</p></li>
</ol>
<p>tools/statistical methods are based on probabilistic models, e.g.:</p>
<p><span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + \epsilon_i\)</span></p>
<p><span class="math inline">\(\epsilon \sim \text{Normal}(\mu = 0, \sigma)\)</span></p>
<p><span class="math inline">\(Y \sim \text{Normal}(\mu = \beta_0 + \beta_1 x, \sigma)\)</span></p>
<p><span class="math inline">\(\hat{y} = E[Y] = \mu = \beta_0 + \beta_1 x\)</span></p>
<p>All models are wrong, some are useful!</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>